import os
import re
import csv
import requests
from bs4 import BeautifulSoup
import time

# This program will scrape a website

def center_text(text): 
    # This function will center the text in the terminal
    terminal_size = os.get_terminal_size().columns
    padding = (terminal_size - len(text)) // 2
    print(' ' * padding + text)
    

def display_data(data):
    # This function will display the scraped data. When the user selects this option, the program will display the data that was scraped from the website.
    if data:
        print('\nData found:')
        print(data)

    else:
        print('No data found.')



def web_scrape():
#    This function will scrape the website and return the data. When the user selects this option, the program will prompt the user to enter a URL. The program will then scrape the website and return the data.
    url = input('Enter the URL: ')
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers) 
        response.raise_for_status()
        print(f'{response.status_code}')
        soup = BeautifulSoup(response.text, 'html.parser')
        print("\nData Successfully Scraped!\n")
        time.sleep(2) 
        return soup.prettify()
    except Exception as i: 
        print(f"Too Bad So Sad Error Found!: {i}")
        return None
    
def regex(data): 
    # this function will search for sensitive data in the scraped data
    patterns = {
        "SSN": re.compile(r"\d{3}-\d{2}-\d{4}"), 
        "Phone Number": re.compile(r"\d{3}-\d{3}-\d{4}"),
        "Email": re.compile(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+"),
        "Credit Card": re.compile(r"\d{4}-\d{4}-\d{4}-\d{4}"),
        "Birthdate": re.compile(r"\d{2}/\d{2}/\d{4}"),
    }
    found = {}
    for key, pattern in patterns.items():
        matches = pattern.findall(data)
        if matches:
            found[key] = matches

    if not found:
        print("No sensitive data found.")
        return None
    
    return found
    



def export_to_csv(data):
    # This function will export the scraped data to a CSV file.
    if data:
        with open('scraped_data.csv', 'w', newline='') as csvfile: 
            writer = csv.writer(csvfile)
            for key, values in data.items():
                writer.writerow([key] + values)
        print("Data successfully saved to scraped_data.csv") 
    else:
        print("No data to export.")


def main_menu():
    # This function will display the main menu and handle user input.
    found_data = False
    data = None
    


    while True:
        center_text("Scraps: Senitive Content Retrieval and Analysis for python Security")
        center_text("Chris D Wise Jr")
        center_text("S01095843@acad.tri-c.edu")

        if found_data:
            print('2. Display scraped data')
            print("3. Export Data to a CSV file")
            print('4. Exit')
        else:
            print('1. Scrape a URL')
            print('4. Exit')


        choice = input('Enter your choice: ')
        if choice == '1'and not found_data:
            data = web_scrape()
            if data:
                found_data = regex(data)
        elif choice == '2' and found_data:
            display_data(data)
        elif choice == '3' and found_data:
            export_to_csv(data)
        elif choice == '4':
            print('Goodbye!')
            break
        else:
            print('Invalid choice. Please try again.')


            
if __name__ == '__main__':
    main_menu()

    
    
    